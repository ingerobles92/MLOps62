{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Performance Visualizations\n",
    "**Author:** Alexis Alduncin  \n",
    "**Date:** October 2024  \n",
    "**Purpose:** Generate publication-quality visualizations for Phase 2 presentation\n",
    "\n",
    "This notebook creates professional visualizations comparing Phase 1 baseline performance with Phase 2 sklearn pipeline improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "print(\"✅ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 2 experimental results\n",
    "results = pd.read_csv('../experiments/baseline_results.csv')\n",
    "results = results.sort_values('Test_MAE')\n",
    "\n",
    "print(f\"Loaded {len(results)} model results\")\n",
    "print(f\"\\nBest model: {results.iloc[0]['Model']}\")\n",
    "print(f\"Best MAE: {results.iloc[0]['Test_MAE']:.2f} hours\")\n",
    "\n",
    "# Display top 5\n",
    "print(\"\\nTop 5 Models:\")\n",
    "print(results[['Model', 'Test_MAE', 'Test_R2', 'CV_MAE']].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1: Comprehensive Phase 2 Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive 4-panel comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Panel 1: MAE Comparison (Top 10)\n",
    "ax1 = axes[0, 0]\n",
    "top_10 = results.head(10)\n",
    "colors = ['green' if x < 4.0 else 'orange' if x < 5.0 else 'red' for x in top_10['Test_MAE']]\n",
    "bars = ax1.barh(range(len(top_10)), top_10['Test_MAE'], color=colors, edgecolor='black', alpha=0.8)\n",
    "ax1.set_yticks(range(len(top_10)))\n",
    "ax1.set_yticklabels(top_10['Model'])\n",
    "ax1.axvline(x=4.0, color='green', linestyle='--', linewidth=2, label='Target MAE = 4.0h', alpha=0.7)\n",
    "ax1.axvline(x=5.44, color='red', linestyle='--', linewidth=2, label='Phase 1 Baseline = 5.44h', alpha=0.7)\n",
    "ax1.set_xlabel('Mean Absolute Error (hours)', fontweight='bold')\n",
    "ax1.set_title('A. Top 10 Models by MAE - Phase 2', fontweight='bold', fontsize=13)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val, model) in enumerate(zip(bars, top_10['Test_MAE'], top_10['Model'])):\n",
    "    improvement = ((5.44 - val) / 5.44) * 100\n",
    "    ax1.text(val + 0.2, i, f'{val:.2f}h ({improvement:+.0f}%)', \n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Panel 2: MAE vs R² Trade-off\n",
    "ax2 = axes[0, 1]\n",
    "scatter = ax2.scatter(results['Test_MAE'], results['Test_R2'], \n",
    "                     s=100, alpha=0.6, c=range(len(results)), cmap='viridis', edgecolors='black')\n",
    "ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax2.axvline(x=4.0, color='green', linestyle='--', alpha=0.5, linewidth=2, label='Target MAE')\n",
    "\n",
    "# Annotate top 5 models\n",
    "for i in range(5):\n",
    "    row = results.iloc[i]\n",
    "    ax2.annotate(row['Model'], \n",
    "                (row['Test_MAE'], row['Test_R2']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "ax2.set_xlabel('MAE (hours)', fontweight='bold')\n",
    "ax2.set_ylabel('R² Score', fontweight='bold')\n",
    "ax2.set_title('B. MAE vs R² Trade-off Analysis', fontweight='bold', fontsize=13)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Training Time vs Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "scatter2 = ax3.scatter(results['Time_sec'], results['Test_MAE'], \n",
    "                      s=100, alpha=0.6, c=range(len(results)), cmap='plasma', edgecolors='black')\n",
    "ax3.axhline(y=4.0, color='green', linestyle='--', alpha=0.5, linewidth=2, label='Target MAE = 4.0h')\n",
    "\n",
    "# Annotate efficient models (good MAE, fast training)\n",
    "efficient = results[(results['Test_MAE'] < 5.0) & (results['Time_sec'] < 0.5)]\n",
    "for _, row in efficient.iterrows():\n",
    "    ax3.annotate(row['Model'], \n",
    "                (row['Time_sec'], row['Test_MAE']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "ax3.set_xlabel('Training Time (seconds)', fontweight='bold')\n",
    "ax3.set_ylabel('MAE (hours)', fontweight='bold')\n",
    "ax3.set_title('C. Efficiency vs Accuracy Trade-off', fontweight='bold', fontsize=13)\n",
    "ax3.set_xscale('log')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 4: Phase 1 vs Phase 2 Improvement\n",
    "ax4 = axes[1, 1]\n",
    "phases = {\n",
    "    'Phase 1\\nLinear Reg\\n(Baseline)': 5.44,\n",
    "    'Phase 1\\nRandom Forest\\n(Best)': 5.33,\n",
    "    'Phase 2\\nSVR\\n(Best Model)': results.iloc[0]['Test_MAE'],\n",
    "    'Phase 2\\nRandomForest\\n(Tuned)': results[results['Model'].str.contains('RandomForest')].iloc[0]['Test_MAE'],\n",
    "    'Target\\n(<4.0h)': 4.0\n",
    "}\n",
    "\n",
    "colors_bar = ['#ff6b6b', '#ff8787', '#51cf66', '#69db7c', '#339af0']\n",
    "bars = ax4.bar(range(len(phases)), phases.values(), color=colors_bar, edgecolor='black', alpha=0.8, linewidth=2)\n",
    "ax4.set_xticks(range(len(phases)))\n",
    "ax4.set_xticklabels(phases.keys(), fontsize=10)\n",
    "ax4.axhline(y=4.0, color='blue', linestyle='--', linewidth=2, alpha=0.5, label='Target Threshold')\n",
    "ax4.set_ylabel('MAE (hours)', fontweight='bold')\n",
    "ax4.set_title('D. Phase 1 vs Phase 2 Performance Evolution', fontweight='bold', fontsize=13)\n",
    "ax4.set_ylim(0, 6)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels with improvement percentages\n",
    "baseline = 5.44\n",
    "for i, (name, val) in enumerate(phases.items()):\n",
    "    if 'Phase' in name:\n",
    "        improvement = ((baseline - val) / baseline) * 100\n",
    "        label = f'{val:.2f}h\\n({improvement:+.1f}%)'\n",
    "        color = 'darkgreen' if improvement > 0 else 'darkred'\n",
    "    elif 'Target' in name:\n",
    "        label = f'{val:.1f}h'\n",
    "        color = 'darkblue'\n",
    "    else:\n",
    "        label = f'{val:.2f}h'\n",
    "        color = 'black'\n",
    "    \n",
    "    ax4.text(i, val + 0.15, label, \n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=10, color=color)\n",
    "\n",
    "# Add goal achievement badge\n",
    "if results.iloc[0]['Test_MAE'] < 4.0:\n",
    "    ax4.text(0.98, 0.95, '✓ GOAL\\nACHIEVED', \n",
    "            transform=ax4.transAxes,\n",
    "            fontsize=14, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', edgecolor='darkgreen', linewidth=3),\n",
    "            ha='right', va='top')\n",
    "\n",
    "plt.suptitle('MLOps Phase 2: Comprehensive Model Performance Analysis', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('phase2_comprehensive_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualization saved: phase2_comprehensive_analysis.png\")\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"  Best Model: {results.iloc[0]['Model']}\")\n",
    "print(f\"  Achievement: MAE = {results.iloc[0]['Test_MAE']:.2f} hours\")\n",
    "print(f\"  Improvement: {((5.44 - results.iloc[0]['Test_MAE']) / 5.44) * 100:.1f}% better than Phase 1\")\n",
    "print(f\"  Goal Status: {'✅ Target Achieved' if results.iloc[0]['Test_MAE'] < 4.0 else '❌ Target Not Met'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2: Model Family Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group models by family\n",
    "def get_model_family(model_name):\n",
    "    if 'Linear' in model_name or 'Ridge' in model_name or 'Lasso' in model_name or 'Elastic' in model_name:\n",
    "        return 'Linear Models'\n",
    "    elif 'RandomForest' in model_name:\n",
    "        return 'Random Forest'\n",
    "    elif 'XGBoost' in model_name:\n",
    "        return 'XGBoost'\n",
    "    elif 'LightGBM' in model_name:\n",
    "        return 'LightGBM'\n",
    "    elif 'Gradient' in model_name:\n",
    "        return 'Gradient Boosting'\n",
    "    elif 'SVR' in model_name:\n",
    "        return 'Support Vector'\n",
    "    elif 'KNN' in model_name:\n",
    "        return 'K-Nearest Neighbors'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "results['Family'] = results['Model'].apply(get_model_family)\n",
    "\n",
    "# Create family comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Best model per family\n",
    "family_best = results.groupby('Family')['Test_MAE'].min().sort_values()\n",
    "colors_family = plt.cm.Set3(np.linspace(0, 1, len(family_best)))\n",
    "\n",
    "bars = ax1.barh(range(len(family_best)), family_best.values, color=colors_family, edgecolor='black', alpha=0.8)\n",
    "ax1.set_yticks(range(len(family_best)))\n",
    "ax1.set_yticklabels(family_best.index)\n",
    "ax1.axvline(x=4.0, color='green', linestyle='--', linewidth=2, label='Target', alpha=0.7)\n",
    "ax1.axvline(x=5.44, color='red', linestyle='--', linewidth=2, label='Baseline', alpha=0.7)\n",
    "ax1.set_xlabel('Best MAE (hours)', fontweight='bold')\n",
    "ax1.set_title('Best Model Performance by Family', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, family_best.values)):\n",
    "    ax1.text(val + 0.15, i, f'{val:.2f}h', va='center', fontweight='bold')\n",
    "\n",
    "# Family performance distribution (boxplot)\n",
    "family_order = family_best.index.tolist()\n",
    "data_for_box = [results[results['Family'] == family]['Test_MAE'].values for family in family_order]\n",
    "\n",
    "bp = ax2.boxplot(data_for_box, labels=family_order, patch_artist=True, showmeans=True)\n",
    "for patch, color in zip(bp['boxes'], colors_family):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "\n",
    "ax2.axhline(y=4.0, color='green', linestyle='--', linewidth=2, label='Target', alpha=0.7)\n",
    "ax2.axhline(y=5.44, color='red', linestyle='--', linewidth=2, label='Baseline', alpha=0.7)\n",
    "ax2.set_ylabel('MAE (hours)', fontweight='bold')\n",
    "ax2.set_title('Model Family Performance Distribution', fontweight='bold')\n",
    "ax2.set_xticklabels(family_order, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('phase2_family_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualization saved: phase2_family_comparison.png\")\n",
    "print(f\"\\nBest performing family: {family_best.index[0]} (MAE: {family_best.values[0]:.2f}h)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 3: Cross-Validation Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CV MAE vs Test MAE to assess generalization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Panel 1: CV MAE vs Test MAE scatter\n",
    "ax1 = axes[0]\n",
    "scatter = ax1.scatter(results['CV_MAE'], results['Test_MAE'], \n",
    "                     s=150, alpha=0.6, c=range(len(results)), \n",
    "                     cmap='coolwarm', edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(results['CV_MAE'].min(), results['Test_MAE'].min())\n",
    "max_val = max(results['CV_MAE'].max(), results['Test_MAE'].max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, alpha=0.5, label='Perfect Generalization')\n",
    "\n",
    "# Annotate top 5\n",
    "for i in range(5):\n",
    "    row = results.iloc[i]\n",
    "    ax1.annotate(row['Model'], \n",
    "                (row['CV_MAE'], row['Test_MAE']),\n",
    "                xytext=(8, 8), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.9,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', alpha=0.5))\n",
    "\n",
    "ax1.set_xlabel('Cross-Validation MAE (hours)', fontweight='bold')\n",
    "ax1.set_ylabel('Test MAE (hours)', fontweight='bold')\n",
    "ax1.set_title('Cross-Validation vs Test Performance', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax1)\n",
    "cbar.set_label('Model Rank (by Test MAE)', fontweight='bold')\n",
    "\n",
    "# Panel 2: Overfitting analysis\n",
    "ax2 = axes[1]\n",
    "top_10 = results.head(10).copy()\n",
    "top_10['Overfit_Gap'] = top_10['Train_MAE'] - top_10['Test_MAE']  # Negative means underfitting\n",
    "\n",
    "colors_overfit = ['green' if x >= -2 else 'orange' if x >= -5 else 'red' for x in top_10['Overfit_Gap']]\n",
    "bars = ax2.barh(range(len(top_10)), top_10['Overfit_Gap'], color=colors_overfit, edgecolor='black', alpha=0.8)\n",
    "ax2.set_yticks(range(len(top_10)))\n",
    "ax2.set_yticklabels(top_10['Model'])\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=2, alpha=0.7)\n",
    "ax2.set_xlabel('Overfitting Gap (Train MAE - Test MAE)', fontweight='bold')\n",
    "ax2.set_title('Overfitting Analysis (Top 10 Models)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Add text annotations\n",
    "for i, (bar, val) in enumerate(zip(bars, top_10['Overfit_Gap'])):\n",
    "    status = 'Good' if val >= -2 else 'Moderate' if val >= -5 else 'High'\n",
    "    ax2.text(val - 0.3 if val < 0 else val + 0.3, i, f'{val:.2f} ({status})', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('phase2_cv_stability_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualization saved: phase2_cv_stability_analysis.png\")\n",
    "print(f\"\\nModels with good generalization (CV ≈ Test): {(abs(results['CV_MAE'] - results['Test_MAE']) < 2).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PHASE 2 RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal Models Evaluated: {len(results)}\")\n",
    "print(f\"\\nBest Model: {results.iloc[0]['Model']}\")\n",
    "print(f\"  - Test MAE: {results.iloc[0]['Test_MAE']:.3f} hours\")\n",
    "print(f\"  - Test RMSE: {results.iloc[0]['Test_RMSE']:.3f} hours\")\n",
    "print(f\"  - Test R²: {results.iloc[0]['Test_R2']:.3f}\")\n",
    "print(f\"  - CV MAE: {results.iloc[0]['CV_MAE']:.3f} hours\")\n",
    "print(f\"  - Training Time: {results.iloc[0]['Time_sec']:.3f} seconds\")\n",
    "\n",
    "baseline_mae = 5.44\n",
    "improvement = ((baseline_mae - results.iloc[0]['Test_MAE']) / baseline_mae) * 100\n",
    "\n",
    "print(f\"\\nImprovement over Phase 1:\")\n",
    "print(f\"  - Phase 1 Baseline: {baseline_mae} hours\")\n",
    "print(f\"  - Phase 2 Best: {results.iloc[0]['Test_MAE']:.2f} hours\")\n",
    "print(f\"  - Improvement: {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nGoal Achievement:\")\n",
    "target = 4.0\n",
    "if results.iloc[0]['Test_MAE'] < target:\n",
    "    print(f\"  ✅ Target MAE < {target}h ACHIEVED\")\n",
    "    print(f\"  Exceeded target by: {target - results.iloc[0]['Test_MAE']:.2f} hours\")\n",
    "else:\n",
    "    print(f\"  ❌ Target MAE < {target}h NOT MET\")\n",
    "    print(f\"  Shortfall: {results.iloc[0]['Test_MAE'] - target:.2f} hours\")\n",
    "\n",
    "print(f\"\\nModels Meeting Target (<{target}h MAE): {(results['Test_MAE'] < target).sum()}\")\n",
    "print(f\"Models Better than Baseline (<{baseline_mae}h MAE): {(results['Test_MAE'] < baseline_mae).sum()}\")\n",
    "\n",
    "print(f\"\\nModel Family Performance:\")\n",
    "for family, mae in results.groupby('Family')['Test_MAE'].min().sort_values().items():\n",
    "    print(f\"  {family}: {mae:.3f} hours\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ ALL VISUALIZATIONS GENERATED SUCCESSFULLY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  1. phase2_comprehensive_analysis.png (4-panel overview)\")\n",
    "print(\"  2. phase2_family_comparison.png (model family analysis)\")\n",
    "print(\"  3. phase2_cv_stability_analysis.png (generalization analysis)\")\n",
    "\n",
    "print(\"\\nRecommended Next Steps:\")\n",
    "print(\"  1. Deploy SVR model to production API\")\n",
    "print(\"  2. Set up monitoring with Evidently\")\n",
    "print(\"  3. Configure automated retraining triggers\")\n",
    "print(\"  4. Implement A/B testing framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
